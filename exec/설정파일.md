# Version

| **Type**       | **Name**      | **Version** | **비고**          |
|----------------|---------------|-------------|-----------------|
| **Frontend**   | React         | 18.2.0      |                 |
| **Frontend**   | NodeJs        | 21          | 프론트 빌드시 사용      |
| **AI**         | YOLO          | 11n         |                 |
| **AI**         | ChatGPT       | 4o-mini     |                 |
| **Backend**    | Java          | 17          |                 |
| **Backend**    | SpringBoot    | 3.4.1       |                 |
| **Backend**    | OpenVidu      | 2.31.0      |                 |
| **DB**         | MySQL         | 8.0.36      |                 |
| **DB**         | MongoDB       | 6.0         |                 |
| **DB**         | PostgreSQL    | 16          | Sonarqube 전용 DB |
| **DB**         | Elasticsearch | 8.3.2       | 운영환경에서만 사용용     |
| **Infra**      | EC2           | t2.xlarge   | SSAFY 에서 제공     |
| **Infra**      | Ubuntu        | 22.04.5     |                 |
| **Infra**      | Jenkins       | 2.492.1     | lts             |
| **Infra**      | SonarQube     | 9.9.8       | lts-community   |
| **Infra**      | Flask         | 3.0.3       |                 |
| **Infra**      | logstash      | 8.3.2       |                 |
| **Infra**      | kibana        | 8.3.2       |                 |
| **Infra**      | filebeat      | 8.3.2       |                 |
| **Infra**      | merticbeat    | 8.3.2       |                 |
| **Infra**      | elastalert2   | 2.23.0      |                 |
| **Management** | Intellij      | 2024.3.3    |                 |
| **Management** | VSCode        | 1.97.2      |                 |

---

# 목차

<aside>

1. [Backend](#Backend)
2. [Backend Code Config](Backend-Code-Config)
3. [Backend For Build](Backend-For-Build)
4. [Frontend](Frontend)
5. [Frontend For Build](Frontend-For-Build)
6. [External Service](External-Service)
7. [EC2](EC2)
8. [DB](DB)
9. [CI/CD](CI/CD)
10. [Code Quality](Code-Quality)
11. [Monitoring](Monitoring)

</aside>

---

# Backend

### **build.gradle**

의존성 관리 파일 입니다. 특이한 점은 SonarQube 를 사용할려면 환경변수를 가져와야 합니다. 이는 빌드할때 값을 줄 수 있으며, 상세한 내용은 SonarQube 문서에 정리되어 있습니다.

```yaml
plugins {
  id 'java'
  id 'org.springframework.boot' version '3.4.1'
  id 'io.spring.dependency-management' version '1.1.7'
  id "org.sonarqube" version "4.0.0.2929"
}

  ext {
  set('springAiVersion', "1.0.0-M5")
}

  sonarqube {
  properties {
  property "sonar.projectKey", System.getenv('SONAR_PROJECT_KEY')
  property "sonar.host.url", System.getenv('SONAR_HOST_URL')
  property "sonar.login", System.getenv('SONAR_LOGIN')
  }
}

  group = 'com.ssafy'
  version = '0.0.1-SNAPSHOT'

  java {
  toolchain {
  languageVersion = JavaLanguageVersion.of(17)
  }
}

  configurations {
  compileOnly {
  extendsFrom annotationProcessor
  }
}

  repositories {
  mavenCentral()
}

  dependencies {
  implementation 'org.springframework.boot:spring-boot-starter-validation'
  implementation 'org.springframework.boot:spring-boot-starter-web'
  implementation 'org.springframework.ai:spring-ai-openai-spring-boot-starter'

  compileOnly 'org.projectlombok:lombok'
  annotationProcessor 'org.projectlombok:lombok'
  testImplementation 'org.springframework.boot:spring-boot-starter-test'
  testRuntimeOnly 'org.junit.platform:junit-platform-launcher'

  // mysql 추가
  implementation 'mysql:mysql-connector-java:8.0.33'
  implementation 'org.springframework.boot:spring-boot-starter-data-jpa'

  // Swagger 추가
  implementation 'org.springdoc:springdoc-openapi-starter-webmvc-ui:2.8.4'
  implementation 'io.swagger.core.v3:swagger-annotations:2.2.28'

  // openvidu 추가
  implementation 'io.openvidu:openvidu-java-client:2.31.0'

  // JASYPT for Encryption
  implementation 'com.github.ulisesbocchio:jasypt-spring-boot-starter:3.0.5'

  // Webflux, mongoDB for chat
  implementation 'org.springframework.boot:spring-boot-starter-webflux'
  implementation 'org.springframework.boot:spring-boot-starter-data-mongodb-reactive'

  // websocket for chat
  implementation 'org.springframework.boot:spring-boot-starter-websocket'

  // Spring Security, OAuth2
  implementation 'org.springframework.boot:spring-boot-starter-security'
  implementation 'org.springframework.security:spring-security-oauth2-client'

  // jwt
  implementation 'io.jsonwebtoken:jjwt-api:0.12.3'
  implementation 'io.jsonwebtoken:jjwt-impl:0.12.3'
  implementation 'io.jsonwebtoken:jjwt-jackson:0.12.3'

  // proj4j
  implementation("org.locationtech.proj4j:proj4j:1.3.0")
  implementation("org.locationtech.proj4j:proj4j-epsg:1.3.0")

  // elasticsearch
  implementation 'org.springframework.boot:spring-boot-starter-data-elasticsearch'

  // HTTP 통신 라이브러리
  implementation 'org.apache.httpcomponents.client5:httpclient5:5.4.2'

  // JSON 직렬화/역직렬화를 위한 Gson
  implementation 'com.google.code.gson:gson:2.12.1'
}

  dependencyManagement {
  imports {
  mavenBom "org.springframework.ai:spring-ai-bom:${springAiVersion}"
  }
}

  tasks.named('test') {
  useJUnitPlatform()
}

```

Backend 에는 환경설정으로 local, prod 가 있습니다. 환경설정 디렉토리 구조는 아래와 같습니다.

```yaml
igeolu
│── src
└── main
├── java
├── resources
├── application.yml
├── application-key.yml
├── application-local.yml
├── application-prod.yml
```

## application

application.yml 파일은 local, prod 로 나누어져 있습니다. 여기서 주요 설정값 보안을 위해 JASYPT 라이브러리를 통한 암호화가 되어있습니다. 복호화 키는 application-key.yml
로 관리되며 이에 대한 보안은 철저하게 지켜져야 합니다.

중요 설정값에 대한 암호화는 [여기서](https://www.devglan.com/online-tools/jasypt-online-encryption-decryption#google_vignette) 진행할 수
있습니다.

### **application.yml**

```yaml
spring:
  application:
    name: igeolu

  profiles:
    group:
      local:
        - local
      prod:
        - prod
    include:
      - key

  servlet:
    multipart:
      max-file-size: 9000MB
      max-request-size: 9000MB

  datasource:
    hikari:
      maximum-pool-size: 20
      minimum-idle: 5

  # openai summary
  ai:
    openai:
      api-key: ENC(uBDSmOPg1tTonPfuaJyCP6yEV0niOAQns3exvyyQ7ZK2ai1qrARYiLh7+hm3IqnzGLb6GSQoL+PPAz13jSYu/BCNBrTv1ITZb7cxh/mfNMkzb+joOJuFMg/Nd1MHHm0H7tMHj1BjOcLidOk5cuhRKtPaA1HTv//OcnJBls0ofpLalYobd7sPPSaQOZTCCX+nu76Sk4EJG/gNvSYWAAleTwZtxP83w6rxrfEggwgFd3Q=)
      chat:
        options:
          model: gpt-4o-mini
          temperature: 0.5
    template:
      path: classpath:prompts/
      cache: true

springdoc:
  swagger-ui:
    path: /api/swagger-ui.html

# clova stt
clova:
  api:
    secret: ENC(omNrA/rg1eXtEsMdx6rAi7IDhZO2Dk2k4RRlWpWLblm0Q4+Q7/PfvDkkM8589G8d)
    invokeUrl: ENC(gE4m6z0zThSjvOIc74HFrV/+fp56WJ9cVcN0IdLMNVCr6PZmuPrSPlxnk6mBHoVlrc59TlTFpFdZ0ZTQXxFKomjZf9m7+t+6UT3mkk98tCIevsMRDCqT+qaskQmn2w88yDkzx7zU5hkje+7o09CppU7kWH3THLVW9ca5Si5IfQg=)

```

### **application-local.yml**

```yaml
spring:
  datasource:
    driver-class-name: com.mysql.cj.jdbc.Driver
    url: jdbc:mysql://mysql:3306/igeolu?useSSL=false&useUnicode=true&serverTimezone=Asia/Seoul&allowPublicKeyRetrieval=true
    username: local
    password: local
  data:
    mongodb:
      # username = local, password = local, dbname = igeolu
      uri: mongodb://local:local@mongodb:27017/igeolu?authSource=admin

  security:
    oauth2:
      client:
        registration:
          kakao:
            client-name: kakao
            client-id: ENC(Az1s8b/I1VHwhQwHPYVI7cQ8LXqTFNc05y+UuAOAJHhEeen0mlMcRaR4aCXnEVLa)
            client-secret: ENC(0sdaWwUcVxpf01vWS1xN72CAq3s3KUYOVLSVhGEpWeFG9Eg9NC+k8jiZBtA0m3Un)
            redirect-uri: "http://localhost:8080/api/login/oauth2/code/kakao"
            authorization-grant-type: authorization_code
            client-authentication-method: client_secret_post
            scope:
              - profile_nickname
        provider:
          kakao:
            authorization-uri: "https://kauth.kakao.com/oauth/authorize"
            token-uri: "https://kauth.kakao.com/oauth/token"
            user-info-uri: "https://kapi.kakao.com/v2/user/me"
            user-name-attribute: id
  jwt:
    secret: vmfhaltmskdlstkfkdgodyroqkfwkdbalroqkfwkdbalaaaaaaaaaaaaaaaabbbbb

  jpa:
    show-sql: true
    hibernate:
      ddl-auto: update
    properties:
      hibernate:
        format_sql: true

kakao:
  logout:
    redirect:
      uri: "http://localhost:8080/api/logout"

openvidu:
  url: http://openvidu:4443
  secret: MY_SECRET

file:
  upload-dir: "/app/igeolu-file"
  base-url: "http://localhost:8080/file"
```

### **application-prod.yml**

```yaml
spring:
  datasource:
    driver-class-name: com.mysql.cj.jdbc.Driver
    url: ENC(Z4z5nNVsr/niF/CAvdZ4W/0KhwmENBW6EjZp808oJVinAWw9YrzpGmtZFU5K2GTHiyzy9RD9W6CioSCb+9EJDcopW0D2jdu2DXE4kDdFMA0=)
    username: ENC(HfwR05w1E/RITtuOu9w04w==)
    password: ENC(LJz0MQqtLrZhbORaBA0Mdg==)
  data:
    mongodb:
      uri: ENC(2TFSKUX5qxvJmH/3Mp4GVd28hTZr132l0dMzBmhqV7/VpcCTlcmNs8t2IgZR4U3FnzreQ2rGpuc7AABGoSJN+H9I72ZGLwGporjrOD+rS2lWJXoqJ1eE7Q==)

  security:
    oauth2:
      client:
        registration:
          kakao:
            client-name: kakao
            client-id: ENC(Az1s8b/I1VHwhQwHPYVI7cQ8LXqTFNc05y+UuAOAJHhEeen0mlMcRaR4aCXnEVLa)
            client-secret: ENC(0sdaWwUcVxpf01vWS1xN72CAq3s3KUYOVLSVhGEpWeFG9Eg9NC+k8jiZBtA0m3Un)
            redirect-uri: "https://i12d205.p.ssafy.io/api/login/oauth2/code/kakao"
            authorization-grant-type: authorization_code
            client-authentication-method: client_secret_post
            scope:
              - profile_nickname
        provider:
          kakao:
            authorization-uri: "https://kauth.kakao.com/oauth/authorize"
            token-uri: "https://kauth.kakao.com/oauth/token"
            user-info-uri: "https://kapi.kakao.com/v2/user/me"
            user-name-attribute: id
  jwt:
    secret: ENC(mUrIeioFDbdSY+cm/TPqIcN4GIqnTauE31oe2zgmn552uW6EmHqoJPovTDq6NGpmPtrlcZvY6Gdt4Iin/c/3sh7HnCMtdZNr4HPCv6o2OIE=)

  jpa:
    show-sql: true
    hibernate:
      ddl-auto: update
    properties:
      hibernate:
        format_sql: true

kakao:
  logout:
    redirect:
      uri: "https://i12d205.p.ssafy.io"

openvidu:
  url: ENC(dHcH9uvYd42Efm/FQf80vH9Q/1a6pRNBZX4YRNISN+t15bmSVSWCGA==)
  secret: ENC(ETKG8ZovYz+lEMiK+WFfilJ9+JrZK5NO)

file:
  upload-dir: "/app/igeolu-file" # 절대 경로 사용을 통한 명확한 파일 위치 지정
  base-url: "https://i12d205.p.ssafy.io/file"

```

### **application-key.yml**

```yaml
# https://www.devglan.com/online-tools/jasypt-online-encryption-decryption#google_vignette
jasypt:
  encryptor:
    bean: jasyptStringEncryptor
    key: **input your key**
```

# Backend Code Config

```yaml
igeolu
├── src
├── main
├── java
├── com.ssafy.igeolu
├── global
├── config
├── ElasticSearchConfig
```

### **ElasticSearchConfig.java**

ElasticSearch DB 연결을 위한 설정파일입니다. ElasticSearch 의 연결설정은 코드로 관리되고 있습니다. ElasticSearch 의 경우 운영환경에서만 실행됩니다.

```java

@Profile("prod")
@Configuration
public class ElasticSearchConfig extends ElasticsearchConfiguration {
	@Override
	@NonNull
	public ClientConfiguration clientConfiguration() {
		return ClientConfiguration.builder()
			.connectedTo("elasticsearch1:9200")
			.build();
	}
}
```

# Backend For Build

Igeolu 는 많은 프로그램에 대해 의존성을 가집니다. 그래서 로컬에서도 간편하고 동일한 환경에서 테스트를 하기위해 docker-compose.yml 를 통해 로컬에서 테스트를 할 수 있게하였습니다.

- `docker-compose up --build` 명령어를 입력하면 로컬에서 테스트를 할 수 있습니다.
- 로컬에서는 Elasticsearch DB 를 사용하지 않습니다. (Elasticsearch 가 무거워서 제외시켰습니다.) 그래서 로컬에서는 Elasticsearch 관련 API(
  `api/properties/sigungu/search` , `/api/properties/search` ) 를 사용할 수 없습니다.

### **docker-compose.yml (for local)**

```yaml
services:
  spring-app:
    build:
      context: .  # Dockerfile이 위치한 폴더
      dockerfile: Dockerfile.local  # Spring Boot Dockerfile 이름
    restart: always
    ports:
      - "8080:8080"  # Spring Boot 애플리케이션 포트 매핑
    environment:
      SPRING_PROFILES_ACTIVE: local  # Spring Boot 활성 프로파일 설정
      TZ: Asia/Seoul
    depends_on:
      - mysql  # MySQL이 먼저 실행되도록 설정
    volumes:
      - igeolu-files:/app/igeolu-file  # 파일 업로드용 볼륨 추가
  mysql:
    image: mysql:8.0.36
    restart: always
    ports:
      - "3300:3306"
    volumes:
      - igeolu-mysql:/var/lib/mysql
    environment:
      MYSQL_DATABASE: igeolu
      MYSQL_USER: local
      MYSQL_PASSWORD: local
      MYSQL_ROOT_PASSWORD: root
      TZ: Asia/Seoul
    command:
      - --character-set-server=utf8mb4
      - --collation-server=utf8mb4_unicode_ci

  mongodb:
    image: mongo:6.0
    container_name: mongodb
    restart: always
    environment:
      MONGO_INITDB_DATABASE: igeolu
      MONGO_INITDB_ROOT_USERNAME: local
      MONGO_INITDB_ROOT_PASSWORD: local
      TZ: Asia/Seoul
    volumes:
      - mongodb_data:/data/db # MongoDB 데이터 저장
      - mongodb_config:/data/configdb # MongoDB 설정 저장
    ports:
      - "27017:27017"

  openvidu:
    image: openvidu/openvidu-dev:2.31.0
    ports:
      - "4443:4443"
    environment:
      - OPENVIDU_SECRET=MY_SECRET
      - OPENVIDU_RECORDING_PATH=/opt/openvidu/recordings
      - OPENVIDU_RECORDING=true
    volumes:
      - openvidu_recordings:/opt/openvidu/recordings
      - /var/run/docker.sock:/var/run/docker.sock  # 호스트 Docker 소켓 마운트

volumes:
  igeolu-mysql:  # MySQL 데이터 저장소
  mongodb_data:
  mongodb_config:
  openvidu_recordings:
  igeolu-files:
```

### **Dockerfile**

운영환경에서 실행되는 Dockerfile 입니다. Jenkins 에서는 해당 파일을 실행해 배포를 진행합니다.

```yaml
FROM openjdk:17-jdk-slim

ARG JAR_FILE=build/libs/*.jar

  # jar 파일 복제
COPY ${JAR_FILE} app.jar

ENV TZ=Asia/Seoul \
LANG=ko_KR.UTF-8

  # prod 모드 실행 명령어
ENTRYPOINT ["java", "-Dspring.profiles.active=prod", "-jar", "app.jar"]
```

# Frontend

### package.json

```yaml
{
  "name": "igeolu",
  "version": "0.1.0",
  "private": true,
  "dependencies": {
    "@radix-ui/react-dialog": "^1.1.6",
    "@stomp/stompjs": "^7.0.0",
    "@tensorflow-models/coco-ssd": "^2.2.3",
    "@tensorflow/tfjs": "^4.22.0",
    "axios": "^1.7.9",
    "cra-template": "1.2.0",
    "date-fns": "^4.1.0",
    "lucide-react": "^0.474.0",
    "openvidu-browser": "^2.31.0",
    "prop-types": "^15.8.1",
    "react": "^18.2.0",
    "react-calendar": "^5.1.0",
    "react-dom": "^18.2.0",
    "react-icons": "^5.4.0",
    "react-kakao-maps-sdk": "^1.1.27",
    "react-router-dom": "^6.28.2",
    "react-scripts": "5.0.1",
    "sockjs-client": "^1.6.1",
    "web-vitals": "^4.2.4"
  },
  "scripts": {
    "start": "react-scripts start",
    "build": "react-scripts build",
    "test": "react-scripts test",
    "eject": "react-scripts eject"
  },
  "eslintConfig": {
    "extends": [
      "react-app",
      "react-app/jest"
    ]
  },
  "browserslist": {
    "production": [
      ">0.2%",
      "not dead",
      "not op_mini all"
    ],
    "development": [
      "last 1 chrome version",
      "last 1 firefox version",
      "last 1 safari version"
    ]
  },
  "proxy": "https://i12d205.p.ssafy.io",
  "devDependencies": {
    "@babel/plugin-proposal-private-property-in-object": "^7.21.11",
    "eslint": "^9.19.0",
    "eslint-plugin-jsx-a11y": "^6.10.2",
    "eslint-plugin-prettier": "^5.2.3",
    "eslint-plugin-react": "^7.37.4",
    "eslint-plugin-react-hooks": "^5.1.0",
    "prettier": "^3.4.2"
  }
}

```

# Frontend For Build

### Dockerfile

- React 빌드를 위해 Node 21 버전을 사용했습니다.
- 빌드된 파일을 nginx 가 서빙할 수 있게 저장하는게 중요합니다.

```yaml
# build stage
FROM node:21 as build-stage
WORKDIR /app
COPY package*.json ./

RUN yarn install
COPY . .
RUN yarn build

  # move file stage
FROM busybox
WORKDIR /build
COPY --from=build-stage /app/build/. .
ADD entrypoint.sh /entrypoint.sh
RUN chmod +x /entrypoint.sh
ENTRYPOINT ["sh", "/entrypoint.sh"]
```

# External Service

## 행정안전부 주소 기반 산업 지원 서비스

도로명주소를 검색하면 위치에 대한 좌표값을 얻어오기 위해 사용합니다.

[https://business.juso.go.kr/addrlink/openApi/apiExprn.do/](https://business.juso.go.kr/addrlink/openApi/apiExprn.do/)

## Kakao OAuth2.0

카카오 소셜로그인을 이용하기위해 사용합니다.

[https://developers.kakao.com/](https://developers.kakao.com/)

## Kakao Map

부동산 매물을 카카오 지도에 띄우기 위해 사용합니다.

[https://apis.map.kakao.com/](https://apis.map.kakao.com/)

## CLOVA Speech

다시보기로 저장된 영상의 음성을 텍스트로 변환하는데 사용합니다.

[https://api.ncloud-docs.com/docs/ai-application-service-clovaspeech](https://api.ncloud-docs.com/docs/ai-application-service-clovaspeech)

## Open AI

GPT 를 이용하여 매물 정보 요약/AI코드리뷰를 사용하는데 필요합니다.

[https://platform.openai.com/docs/overview/](https://platform.openai.com/docs/overview/)

# EC2

EC2 서버에 띄워진 컨테이너는 모두 `igeolu-network` 를 사용해 통신하고 있습니다. 이는 외부에서 접근을 막고 보안성을 높입니다.

```bash
docker network create igeolu-network
```

호스트에 볼륨으로 설정되는 폴더의 경우, 해당 폴더 권한이 `root` 면 컨테이너에서 접근이 불가능할 수 있습니다. 따라서 해당 폴더에 권한을 부여하는데 아래 2가지 방법으로 권한부여가 가능합니다.

```bash
// 방법 1
sudo chown -R 1000:1000 /jenkins

// 방법 2
sudo chmod -R 755 /path/to/jenkins_data
```

개인적으로 가독성 때문에 yml 작성방식을 선호하여 Dockfile 보다는 Docker-compose 를 이용해 많이 작성했습니다.

# DB

### mysql-docker-compose.yml

- 3306 은 흔한 포트이어서 해킹위험을 줄이고자 12206 으로 설정했습니다. 도커 내부 네트워크를 사용해도 되지만 외부에서 MySql Workbench 로 관리하기 위해 포트를 열어놨습니다.

```yaml
services:
  mysql:
    image: mysql:8.0.36
    restart: always
    ports:
      - "12206:3306"
    volumes:
      - igeolu-mysql:/var/lib/mysql  # 볼륨 참조
    environment:
      MYSQL_ROOT_PASSWORD: your password
      MYSQL_DATABASE: your db name
      TZ: Asia/Seoul
    networks:
      - igeolu_network
    command:
      - --character-set-server=utf8mb4
      - --collation-server=utf8mb4_unicode_ci

volumes:
  igeolu-mysql:  # 볼륨 선언

networks:
  igeolu_network:
    external: true

```

### mongodb-docker-compose.yml

- 27017은 흔한 포트이어서 해킹위험을 줄이고자 27222 으로 설정했습니다. 도커 내부 네트워크를 사용해도 되지만 외부에서 MongoDB Compass 로 관리하기 위해 포트를 열어놨습니다.

```yaml
services:
  mongodb:
    image: mongo:6.0
    container_name: mongodb
    environment:
      MONGO_INITDB_ROOT_USERNAME: igeolu
      MONGO_INITDB_ROOT_PASSWORD: igeolu
      TZ: Asia/Seoul
    volumes:
      - /igeolu-mongo/mongodb_data:/data/db # MongoDB 데이터 저장
      - /igeolu-mongo/mongodb_config:/data/configdb # MongoDB 설정 저장
    ports:
      - "27222:27017"
    networks:
      - igeolu_network

networks:
  igeolu_network:
    external: true

```

# CI/CD

### jenkins-docker-compose.yml

- Jenkins 를 도커로 띄울시, DooD 방식을 사용하기위해 Jenkins 컨테이너에 접속해서 Docker 설치 및 docker.sock 사용을 위한 권한부여가 필요합니다.

```yaml
 services:
   jenkins:
     image: jenkins/jenkins:lts
     container_name: jenkins
     volumes:
       - /var/run/docker.sock:/var/run/docker.sock
       - /jenkins:/var/jenkins_home
     networks:
       - igeolu_network
     environment:
       - JENKINS_OPTS=--prefix=/jenkins

 networks:
   igeolu_network:
     external: true
```

Jenkins 내부 도커 설치 명령어

```bash
docker exec -u root -it [container] /bin/bash

apt-get update -y
apt-get install -y
apt-get install docker.io -y
```

### nginx-docker-compose.yml

- https 의 경우 let’s encrypt 인증서와 certbot 을 이용해 발급을 했습니다.
- igeolu-frontend 의 경우 React 로 빌드한 정적파일을 저장하여 배포합니다.
- igeolu-file 의 경우 사용자가 업로드한 파일을 제공합니다.

```yaml
services:
  nginx:
    image: nginx:1.25.4
    container_name: nginx
    ports:
      - "80:80"
      - "443:443"
    environment:
      TZ: "Asia/Seoul"
    volumes:
      - /igeolu-nginx/nginx:/etc/nginx/conf.d
      - /igeolu-nginx/certbot/conf:/etc/letsencrypt
      - /igeolu-nginx/certbot/www:/var/www/certbot
      - /igeolu-frontend/build:/usr/share/nginx/html
      - /igeolu-file:/igeolu-file
    depends_on:
      - certbot
    networks:
      - igeolu_network

  certbot:
    image: certbot/certbot
    volumes:
      - /igeolu-nginx/certbot/conf:/etc/letsencrypt
      - /igeolu-nginx/certbot/www:/var/www/certbot
    networks:
      - igeolu_network

networks:
  igeolu_network:
    external: true

```

### .conf

- http 연결 요청시 `308 https://$host$request_uri;` 처럼 308로 요청해야 HTTP 메서드 변경이 없습니다. 301 로 할시 POST → GET 으로 변경될 수 있습니다.
- 파일 저장시 `client_max_body_size` `client_body_buffer_size` 설정이 필요합니다.
- igeolu 는 관리자 프로그램도 포트가 아닌 url 로 접속합니다. 관리자만 접근해야하는 프로그램의 경우 `allow_ip` 에 적힌 ip 만 접근 가능하게하여 보안을 높였습니다.
- WebSocket 연결시 `proxy_read_timeout` , `proxy_send_timeout` 를 따로 설정해주어야 자동으로 끊기지 않습니다.

```yaml

# nginx websocket 활용 설정
  map $http_upgrade $connection_upgrade {
  default upgrade;
  '' close;
  }
  server {
  listen 80;
  server_name i12d205.p.ssafy.io igeolu.com;
  server_tokens off;

  # 인증서 발급을 위한 경로
  location /.well-known/acme-challenge/ {
  root /var/www/certbot;
  }

  # HTTP 요청을 HTTPS로 리디렉션
  location / {
  return 308 https://$host$request_uri;
  }
}

  server {
  listen 443 ssl;
  server_name i12d205.p.ssafy.io igeolu.com;
  server_tokens off;

  # SSL 인증서 경로
  ssl_certificate /etc/letsencrypt/live/i12d205.p.ssafy.io/fullchain.pem;
  ssl_certificate_key /etc/letsencrypt/live/i12d205.p.ssafy.io/privkey.pem;

  # 정적 파일(React 앱) 제공
  location / {
  root /usr/share/nginx/html;
  index index.html;
  try_files $uri /index.html;
  }

  # 파일 요청 프록시
  location /file/ {
  alias  /igeolu-file/;  # 파일이 저장된 실제 경로
  expires max;  # 캐싱 설정
  }

  # API 요청 리버스 프록시
  # Spring Boot
  location /api/ {
  proxy_pass http://igeolu-backend:8080; # 백엔드 컨테이너의 이름과 포트
  # proxy_pass https://naver.com;
  proxy_set_header Host $host;
  proxy_set_header X-Real-IP $remote_addr;
  proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

  #this is the maximum upload size
  client_max_body_size       10m;
  client_body_buffer_size    128k;

}

  # WebSocket 요청 처리
  location ~ ^/api/(chats/ws|sub|pub)$ {
  proxy_pass http://igeolu-backend:8080;
  # proxy_pass https://naver.com; 
  proxy_http_version 1.1;
  proxy_set_header Upgrade $http_upgrade;
  proxy_set_header Connection "Upgrade";
  proxy_set_header Host $host;

  proxy_read_timeout 3600000; # 1 * 60 * 60 * 1000
  proxy_send_timeout 3600000; # 1 * 60 * 60 * 1000

}

  # Swagger
  location /v3 {
  proxy_pass http://igeolu-backend:8080;
  # proxy_pass https://naver.com;
  proxy_set_header Host $host;
  proxy_set_header X-Real-IP $remote_addr;
  proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

}

  # Python Review
  location /webhook {
  proxy_pass http://review-server:5000; # Python
  proxy_set_header Host $host;
  proxy_set_header X-Real-IP $remote_addr;
  proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

  include conf.d/allow_ip;
  deny all;
  }

  # SonarQube
  location /sonarqube {
  proxy_pass http://sonarqube:9000; # sonarqube

  proxy_set_header Host $host;
  proxy_set_header X-Real-IP $remote_addr;
  proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
  proxy_set_header X-Forwarded-Proto $scheme;
  proxy_redirect off;  # 프록시 리디렉션을 비활성화하여, SonarQube에서 올바른 URL로 리디렉션 되도록 처리

  include conf.d/allow_ip;
  deny all;
  }

  # Jenkins
  location /jenkins {
  proxy_pass http://jenkins:8080; # jenkins
  proxy_redirect     default;

  proxy_set_header Host $host;
  proxy_set_header X-Real-IP $remote_addr;
  proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
  proxy_max_temp_file_size 0;

  # Required for Jenkins websocket agents
  proxy_set_header   Connection        $connection_upgrade;
  proxy_set_header   Upgrade           $http_upgrade;

  #this is the maximum upload size
  client_max_body_size       10m;
  client_body_buffer_size    128k;

  include conf.d/allow_ip;
  deny all;
  }

  # kibana
  location /kibana {
  proxy_pass http://kibana:5601;
  proxy_set_header Host $host;
  proxy_set_header X-Real-IP $remote_addr;
  proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
  proxy_set_header X-Forwarded-Proto $scheme;

  include conf.d/allow_ip;
  deny all;

  }
}

```

# Code Quality

### sonarqube-docker-compose.yml

- Sonarqube 의 경우 PostgreSQL 를 이용해 데이터를 저장합니다.
- Sonarqube 프로그램의 경우 무겁기때문에 사용자 컴퓨터 성능에 따른 제한이 있을 수 있습니다.

```yaml
services:
  sonarqube:
    image: sonarqube:lts-community
    depends_on:
      - sonardb
    container_name: sonarqube
    expose:
      - "9000"
    environment:
      TZ: Asia/Seoul
      SONAR_WEB_CONTEXT: /sonarqube
      SONAR_JDBC_URL: jdbc:postgresql://sonardb:5432/sonar
      SONAR_JDBC_USERNAME: your name
      SONAR_JDBC_PASSWORD: your password
    volumes:
      - /igeolu-sonar/sonarqube_data:/opt/sonarqube/data
      - /igeolu-sonar/sonarqube_extensions:/opt/sonarqube/extensions
      - /igeolu-sonar/sonarqube_logs:/opt/sonarqube/logs
    networks:
      - igeolu_network

  sonardb:
    image: postgres:16
    environment:
      POSTGRES_USER: your name
      POSTGRES_PASSWORD: your password
    volumes:
      - /igeolu-sonar/postgresql:/var/lib/postgresql
      - /igeolu-sonar/postgresql_data:/var/lib/postgresql/data
    networks:
      - igeolu_network

networks:
  igeolu_network:
    external: true

```

### review-docker-compose.yml

- 해당 AI코드리뷰 서버는 제가 직접 만들어서 Docker Hub 에 올려두었습니다.
- GPT API KEY 의 경우 본인 GPT 키 값을 넣어야 합니다.
- GITLAB_TOKEN 의 경우 본인 프로젝트 토큰값을 넣어야 합니다.

```yaml
services:
  review-server:
    image: g22206/review-server:latest  # Docker Hub에서 이미지를 가져옵니다.
    expose:
      - "5000"
    environment:
      GPT_API_KEY: "your gpt key"
      GITLAB_TOKEN: "your gitlab token"
    restart: always
    networks:
      - igeolu_network

networks:
  igeolu_network:
    external: true

```

# Monitoring

### elk-docker-compose.yml

- elasticsearch 의 경우 보통 클러스터를 구성해서 사용하지만, 현재 EC2 의 메모리가 매우 부족한 관계로 싱글노드로 구성하였습니다.
- logstash 의 경우 MySql 데이터와 주기적으로 동기화 하기위해 `mysql-connector-j-8.0.33.jar` 파일이 필요합니다.
- filebeat 의 `igeolu-logs` 에는 spring 의 `logback-spring.xml` 을 통해 저장된 로그파일이 있습니다.

```yaml
services:
  elasticsearch1:
    image: elasticsearch:8.3.2
    container_name: elasticsearch1
    volumes:
      - ./elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml
      - ./es_data/elasticsearch1:/usr/share/elasticsearch/data
      - ./es_plugins:/usr/share/elasticsearch/plugins
    environment:
      - ES_JAVA_OPTS=-Xms1024m -Xmx1024m
      - xpack.security.enabled=false
      - bootstrap.memory_lock=true
      - node.name=elasticsearch1
      - cluster.name=elk-cluster
      - discovery.type=single-node  # Set to single-node for standalone mode
      - TZ=Asia/Seoul
    mem_limit: 4g
    ulimits:
      memlock:
        soft: -1
        hard: -1
    networks:
      - igeolu_network
    ports:
      - "9200:9200"  # External port 9200 mapped to internal port 9200

  logstash:
    image: logstash:8.3.2
    container_name: logstash
    volumes:
      - ./logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml
      - ./logstash/mysql-connector-j-8.0.33.jar:/usr/share/logstash/mysql-connector-j-8.0.33.jar
      - ./logstash/last_run_metadata:/usr/share/logstash/last_run_metadata
      - ./logstash/pipeline:/usr/share/logstash/pipeline
      - ./logstash/config/pipelines.yml:/usr/share/logstash/config/pipelines.yml
      - ./logstash/template:/usr/share/logstash/template
    depends_on:
      - elasticsearch1
    environment:
      - TZ=Asia/Seoul
    networks:
      - igeolu_network

  kibana:
    image: kibana:8.3.2
    container_name: kibana
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch1:9200
      - SERVER_BASEPATH=/kibana
      - SERVER_REWRITEBASEPATH=true
      - TZ=Asia/Seoul
    networks:
      - igeolu_network
    depends_on:
      - elasticsearch1

  filebeat:
    image: docker.elastic.co/beats/filebeat:8.3.2
    container_name: filebeat
    volumes:
      - /igeolu-logs/backend:/var/log/backend:ro
      - ./filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml
    networks:
      - igeolu_network
    depends_on:
      - logstash

  metricbeat:
    image: docker.elastic.co/beats/metricbeat:8.3.2
    container_name: metricbeat
    hostname: "igeolu-ec2"
    user: root
    volumes:
      - ./metricbeat/metricbeat.yml:/usr/share/metricbeat/metricbeat.yml
      - /proc:/hostfs/proc:ro
      - /sys/fs/cgroup:/hostfs/sys/fs/cgroup:ro
      - /:/hostfs:ro
      - /var/run/dbus/system_bus_socket:/hostfs/var/run/dbus/system_bus_socket:ro
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch1:9200
      - DBUS_SYSTEM_BUS_ADDRESS=unix:path=/hostfs/var/run/dbus/system_bus_socket
      - TZ=Asia/Seoul
    command: [ "--strict.perms=false" ]
    networks:
      - igeolu_network


networks:
  igeolu_network:
    external: true

```

## Elasticsearch

### elasticsearch.yml

```yaml
cluster.name: "elk-cluster"
network.host: 0.0.0.0

# For single node setup
discovery.type: single-node
```

### plugins

자동완성검색을 위한 Nori 형태소 분석기 설치

https://www.elastic.co/guide/en/elasticsearch/plugins/current/analysis-nori.html

자동완성검색을 위한 자소 분석기 설치

https://github.com/netcrazy/elasticsearch-jaso-analyzer/tree/v8.3.2

## logstash

### logstash.yml

```yaml
http.host: "0.0.0.0"

# 모니터링 노드
xpack.monitoring.elasticsearch.hosts: [ "http://elasticsearch1:9200" ]
```

### pipeline.yml

- sigungu 의 경우 최초의 한번만 동기화 하고 업데이트 될 일이 없어서 그 이후로는 주석처리를 했습니다.

```yaml
- pipeline.id: product
  path.config: "/usr/share/logstash/pipeline/property.conf"
- pipeline.id: backend
  path.config: "/usr/share/logstash/pipeline/backend.conf"
# - pipeline.id: sigungu
# path.config: "/usr/share/logstash/pipeline/sigungu.conf"
```

### property.conf

- MySQL 에 있는 매물과 데이터에 대해 elasticsearch 와 동기화하는 설정입니다.

```json
input {
  jdbc {
  jdbc_connection_string
  =>
  "jdbc:mysql://mysql:3306/igeolu"
  jdbc_user
  =>
  "root"
  jdbc_password
  =>
  "igeolu"
  jdbc_driver_library
  =>
  "/usr/share/logstash/mysql-connector-j-8.0.33.jar"
  jdbc_driver_class
  =>
  "com.mysql.cj.jdbc.Driver"
  schedule
  =>
  "* * * * *"
  statement
  =>
  "
  SELECT
  p.id,
  p.description,
  p.deposit,
  p.monthly_rent,
  p.area,
  p.current_floor,
  p.total_floors,
  p.address,
  p.latitude,
  p.longitude,
  p.created_at,
  p.updated_at,
  p.approval_date,
  p.user_id,
  d.dong_code,
  d.sido_name,
  d.gugun_name,
  d.dong_name,
  UNIX_TIMESTAMP(p.updated_at)
  AS
  unix_ts_in_secs,
  (SELECT
  GROUP_CONCAT(DISTINCT
  po.option_id)
  FROM
  property_option
  po
  WHERE
  po.property_id
  =
  p.id)
  AS
  option_ids,
  (SELECT
  GROUP_CONCAT(DISTINCT
  pi.file_path)
  FROM
  property_image
  pi
  WHERE
  pi.property_id
  =
  p.id)
  AS
  image_urls
  FROM
  property
  p
  LEFT
  JOIN
  dongcodes
  d
  ON
  p.dong_code
  =
  d.dong_code
  WHERE
  (UNIX_TIMESTAMP(p.updated_at)
  >: sql_last_value
  AND
  p.updated_at
  <
  NOW())
  ORDER
  BY
  p.updated_at
  ASC
  ;
  "
  tracking_column
  =>
  "unix_ts_in_secs"
  use_column_value
  =>
  true
  tracking_column_type
  =>
  "numeric"
  last_run_metadata_path
  =>
  "/usr/share/logstash/last_run_metadata/.logstash_property_dummy"
}
}

filter {
date {
match => ["date", "yyyy-MM-dd HH"]
timezone => "Asia/Seoul"
}

mutate {
remove_field => ["unix_ts_in_secs"]
}
# `option_ids`를 쉼표 기준으로 분리하여 배열로 변환
mutate {
split => {"option_ids" => ","}
}

# `option_ids` 배열의 각 요소를 정수형으로 변환
mutate {
convert => {"option_ids" => "integer"}
}

# `image_urls`를 쉼표 기준으로 분리하여 배열로 변환
mutate {
split => {"image_urls" => ","}
}
}

output {
elasticsearch {
hosts => [
"http://elasticsearch1:9200"
]
index => "property-1"
template => "/usr/share/logstash/template/property.json"
template_name => "property"
template_overwrite => true
}
}

```

### property.json

- MySql 에 있는 부동산 매물과, elasticsearch 에 저장하기 위해 매핑해주는 파일입니다.

```json
{
  "index_patterns": [
    "property-*"
  ],
  "template": {
    "settings": {
      "number_of_shards": 1,
      "number_of_replicas": 1
    },
    "mappings": {
      "properties": {
        "id": {
          "type": "integer"
        },
        "description": {
          "type": "text"
        },
        "deposit": {
          "type": "integer"
        },
        "monthly_rent": {
          "type": "integer"
        },
        "area": {
          "type": "double"
        },
        "current_floor": {
          "type": "integer"
        },
        "total_floors": {
          "type": "integer"
        },
        "address": {
          "type": "text",
          "fields": {
            "keyword": {
              "type": "keyword",
              "ignore_above": 256
            }
          }
        },
        "sido_name": {
          "type": "text"
        },
        "gugun_name": {
          "type": "text"
        },
        "dong_name": {
          "type": "text"
        },
        "dong_code": {
          "type": "keyword"
        },
        "latitude": {
          "type": "double"
        },
        "longitude": {
          "type": "double"
        },
        "approval_date": {
          "type": "date",
          "format": "yyyy-MM-dd||strict_date_optional_time||epoch_millis"
        },
        "created_at": {
          "type": "date",
          "format": "yyyy-MM-dd'T'HH:mm:ss.SSSSSS||strict_date_optional_time||epoch_millis"
        },
        "updated_at": {
          "type": "date",
          "format": "yyyy-MM-dd'T'HH:mm:ss.SSSSSS||strict_date_optional_time||epoch_millis"
        },
        "user_id": {
          "type": "long"
        },
        "image_urls": {
          "type": "keyword"
        },
        "option_ids": {
          "type": "integer"
        }
      }
    }
  },
  "priority": 1,
  "version": 1
}

```

### sigungu.conf

```json
input {
  jdbc {
  jdbc_connection_string
  =>
  "jdbc:mysql://mysql:3306/igeolu"
  jdbc_user
  =>
  "root"
  jdbc_password
  =>
  "igeolu"
  jdbc_driver_library
  =>
  "/usr/share/logstash/mysql-connector-j-8.0.33.jar"
  jdbc_driver_class
  =>
  "com.mysql.cj.jdbc.Driver"
  schedule
  =>
  "* * * * *"
  statement
  =>
  "
  SELECT
  p.id,
  p.description,
  p.deposit,
  p.monthly_rent,
  p.area,
  p.current_floor,
  p.total_floors,
  p.address,
  p.latitude,
  p.longitude,
  p.created_at,
  p.updated_at,
  p.approval_date,
  p.user_id,
  d.dong_code,
  d.sido_name,
  d.gugun_name,
  d.dong_name,
  UNIX_TIMESTAMP(p.updated_at)
  AS
  unix_ts_in_secs,
  (SELECT
  GROUP_CONCAT(DISTINCT
  po.option_id)
  FROM
  property_option
  po
  WHERE
  po.property_id
  =
  p.id)
  AS
  option_ids,
  (SELECT
  GROUP_CONCAT(DISTINCT
  pi.file_path)
  FROM
  property_image
  pi
  WHERE
  pi.property_id
  =
  p.id)
  AS
  image_urls
  FROM
  property
  p
  LEFT
  JOIN
  dongcodes
  d
  ON
  p.dong_code
  =
  d.dong_code
  WHERE
  (UNIX_TIMESTAMP(p.updated_at)
  >: sql_last_value
  AND
  p.updated_at
  <
  NOW())
  ORDER
  BY
  p.updated_at
  ASC
  ;
  "
  tracking_column
  =>
  "unix_ts_in_secs"
  use_column_value
  =>
  true
  tracking_column_type
  =>
  "numeric"
  last_run_metadata_path
  =>
  "/usr/share/logstash/last_run_metadata/.logstash_property_dummy"
}
}

filter {
date {
match => ["date", "yyyy-MM-dd HH"]
timezone => "Asia/Seoul"
}

mutate {
copy => {"id" => "[@metadata][_id]"}
remove_field => ["id", "@version", "unix_ts_in_secs"]
}
# `option_ids`를 쉼표 기준으로 분리하여 배열로 변환
mutate {
split => {"option_ids" => ","}
}

# `option_ids` 배열의 각 요소를 정수형으로 변환
mutate {
convert => {"option_ids" => "integer"}
}

# `image_urls`를 쉼표 기준으로 분리하여 배열로 변환
mutate {
split => {"image_urls" => ","}
}
}

output {
elasticsearch {
hosts => [
"http://elasticsearch1:9200"
]
index => "property-1"
template => "/usr/share/logstash/template/property.json"
template_name => "property"
template_overwrite => true
document_id => "%{[@metadata][_id]}"
}
}

```

### sigungu.json

- MySql 에 있는 시군구 정보와, elasticsearch 에 저장하기 위해 매핑해주는 파일입니다.
- 저장시 자동검색어완성 지원 하기 위해 여러가지 분석기를 통해 저장합니다.

```json
{
  "index_patterns": [
    "sigungu-*"
  ],
  "template": {
    "settings": {
      "number_of_shards": 1,
      "number_of_replicas": 1,
      "max_ngram_diff": 30,
      "analysis": {
        "filter": {
          "suggest_filter": {
            "type": "edge_ngram",
            "min_gram": 1,
            "max_gram": 50
          }
        },
        "analyzer": {
          "ngram-sigungu": {
            "type": "custom",
            "tokenizer": "partial"
          },
          "edge-sigungu": {
            "type": "custom",
            "tokenizer": "edge"
          },
          "suggest_index_analyzer": {
            "type": "custom",
            "tokenizer": "jaso_index_tokenizer",
            "filter": [
              "suggest_filter"
            ]
          }
        },
        "tokenizer": {
          "partial": {
            "type": "ngram",
            "min_gram": 2,
            "max_gram": 30,
            "token_chars": [
              "letter",
              "digit"
            ]
          },
          "edge": {
            "type": "edge_ngram",
            "min_gram": 1,
            "max_gram": 30,
            "token_chars": [
              "letter",
              "digit"
            ]
          },
          "jaso_index_tokenizer": {
            "type": "jaso_tokenizer",
            "mistype": true,
            "chosung": true
          }
        }
      }
    },
    "mappings": {
      "_source": {
        "excludes": [
          "sigungu_jaso"
        ]
      },
      "properties": {
        "sigungu": {
          "type": "keyword",
          "copy_to": [
            "sigungu-jaso"
          ],
          "fields": {
            "kor": {
              "type": "text",
              "analyzer": "nori"
            },
            "edge": {
              "type": "text",
              "analyzer": "edge-sigungu"
            },
            "partial": {
              "type": "text",
              "analyzer": "ngram-sigungu"
            }
          }
        },
        "sigungu-jaso": {
          "type": "text",
          "analyzer": "suggest_index_analyzer"
        }
      }
    }
  },
  "priority": 1,
  "version": 1
}

```

### backend.conf

- springboot 서버에서 저장한 로그들을 filebeat 가 수집하고, 이를 logstash 가 받아서 elasticsearch 로 보내는 설정입니다.

```json
input {
  beats {
  port
  =>
  5044
}
}

## Add your filters / logstash plugins configuration here

output {
elasticsearch {
hosts => [
"http://elasticsearch1:9200"
]
index => "backend-%{+yyyy.MM.dd}"
ecs_compatibility => disabled
}
}

```

## Kibana

### kibana.yml

```yaml
server.host: "0.0.0.0"
server.shutdownTimeout: "5s"
elasticsearch.hosts: [ "http://elasticsearch1:9200" ]
monitoring.ui.container.elasticsearch.enabled: true
```

## FileBeat

### filebeat.yml

- springboot 로그 파일을 수집합니다.

```yaml
filebeat.inputs:
  - type: log
    enabled: true
    paths:
      - /var/log/backend/*/*.log  # 로그 파일 경로

output.logstash:
  hosts: [ "logstash:5044" ]  # Logstash로 로그 전송
```

## MetricBeat

### metricbeat.yml

- 10초 간격으로 호스트의 정보를 수집합니다.
- `setup.dashboards.enabled: true` 사용시 kibana 에서 기본 대시보드를 이용할 수 있습니다.

```yaml
metricbeat.modules:
  - module: system
    metricsets:
      - cpu
      - memory
      - network
      - diskio
      - filesystem
      - process
      - load
    period: 10s

setup.dashboards.enabled: true
setup.kibana:
  host: "http://kibana:5601/kibana"

output.elasticsearch:
  hosts: [ "http://elasticsearch1:9200" ]

processors:
  - add_host_metadata: ~
  - add_cloud_metadata: ~
  - add_docker_metadata: ~
```

## ElastAlert2

### elastalert-docker-compose.yml

```yaml
services:
  elastalert:
    image: jertel/elastalert2:2.23.0
    container_name: elastalert
    volumes:
      - ./elastalert/elastalert.yaml:/opt/elastalert/config.yaml
      - ./elastalert/rules:/opt/elastalert/rules
    networks:
      - igeolu_network

networks:
  igeolu_network:
    external: true
```

### elastalert.yaml

- elastalert 에서 사용되는 설정 파일의 기본 확장자는 `yaml` 입니다. `yml` 을 사용할시 인식이 안되니 주의가 필요합니다.
- 10초 주기로 확인하여 트리거에 해당되는게 있으면 알람을 보내도록 설정했습니다.

```yaml
rules_folder: /opt/elastalert/rules

run_every:
  seconds: 10

buffer_time:
  minutes: 15

es_host: elasticsearch1
es_port: 9200

writeback_index: elastalert_status

alert_time_limit:
  days: 2

```

### host-cpu-alert.yml

- 1분간 cpu 평균 사용량이 300% 를 넘어가면 알람을 보냅니다. Linux unbuntu 의 경우 cpu 코어 수마다 % 가 계산되서, cpu 코어가 4개면 400% 까지 사용가능합니다.

```yaml
name: "CPU Usage Alert"
type: "metric_aggregation"
index: ".ds-metricbeat-*"
is_enabled: true

buffer_time:
  minutes: 3
metric_agg_key: "system.cpu.total.pct"
metric_agg_type: avg
bucket_interval:
  minutes: 1
sync_bucket_interval: true
max_threshold: 3.0

filter:
  - query:
      query_string:
        query: "system.cpu.total.pct:*"

realert:
  minutes: 3

metric_format_string: "{:.3%}"

alert_text_type: alert_text_only
alert_subject: ":kirby_shake: EC2 CPU 사용량 경고 :kirby_shake:"
alert_text: ""

alert:
  - "mattermost"
mattermost_webhook_url: "https://meeting.ssafy.com/hooks/swkrw6fka7yxtyd3jxy96ejfne"
mattermost_channel_override: "ProjectAlarm"
mattermost_msg_color: "danger"
mattermost_msg_fields:
  - title: ":kirby_shake: 대성아 고쳐줘.. :kirby_shake:"
    value: ":kirby_bounce_rainbow: 서버가 갑자기 열일하는중 \n:kirby_bounce_rainbow: 서버가 이런적이 없는데??\n:kirby_bounce_rainbow: 현재 CPU 사용량: {0}"
    short: false
    args: [ "metric_agg_value_formatted" ]

```

### host-cpu-peak-alert.yml

- cpu 사용률이 순간적으로 390% 이상 사용시 알람을 보냅니다. 이는 서버가 죽었을 가능성이 있습니다.

```yaml
name: "CPU Usage Peak Alert"
type: "metric_aggregation"
index: ".ds-metricbeat-*"
is_enabled: false

buffer_time:
  minutes: 3
metric_agg_key: "system.cpu.total.pct"
metric_agg_type: max
max_threshold: 3.9

filter:
  - query:
      query_string:
        query: "system.cpu.total.pct:*"

realert:
  minutes: 3

metric_format_string: "{:.3%}"

alert_text_type: alert_text_only
alert_subject: ":cat_feed: EC2 CPU 사용량 경고 :cat_feed:"
alert_text: ""

alert:
  - "mattermost"
mattermost_webhook_url: "https://meeting.ssafy.com/hooks/swkrw6fka7yxtyd3jxy96ejfne"
mattermost_channel_override: "ProjectAlarm"
mattermost_msg_color: "danger"
mattermost_msg_fields:
  - title: ":cat_feed: 쵸비이이이이이상!!! :cat_feed:"
    value: ":robot_cleaner_cat: 이 메세지가 서버의 마지막 유언입니다.\n:robot_cleaner_cat: CPU 390% 이상 사용 - 터지기 직전!\n:robot_cleaner_cat: 현재 CPU 사용량: {0}"
    short: false
    args: [ "metric_agg_value_formatted" ]

```

### host-memory-alert.yml

- 3분간 memory 사용량이 92% 이상 사용하면 알람을 보냅니다.

```yaml
name: "Memory Usage Alert"
type: "metric_aggregation"
index: ".ds-metricbeat-*"
is_enabled: true

buffer_time:
  minutes: 3
metric_agg_key: "system.memory.used.pct"
metric_agg_type: avg
bucket_interval:
  minutes: 3
sync_bucket_interval: true
max_threshold: 0.92

filter:
  - query:
      query_string:
        query: "system.memory.used.pct:*"

realert:
  minutes: 3

metric_format_string: "{:.3%}"

alert_text_type: alert_text_only
alert_subject: ":kirby_shake: EC2 메모리 사용량 경고 :kirby_shake:"
alert_text: ""

alert:
  - "mattermost"
mattermost_webhook_url: "https://meeting.ssafy.com/hooks/swkrw6fka7yxtyd3jxy96ejfne"
mattermost_channel_override: "ProjectAlarm"
mattermost_msg_color: "danger"
mattermost_msg_fields:
  - title: ":kirby_shake: 진훈아 일어나.. :kirby_shake:"
    value: ":kirby_bounce_rainbow: 지금 잠이 오세요???\n:kirby_bounce_rainbow: 서버가 아프다구요!!!\n:kirby_bounce_rainbow: 현재 메모리 사용량: {0}"
    short: false
    args: [ "metric_agg_value_formatted" ]

```

### host-memory-peak-alert.yml

- RAM 사용량이 순간적으로 98% 이상 사용시 알람을 보냅니다. 이는 서버가 죽었을 가능성이 있습니다.

```yaml
name: "Memory Usage Peak Alert"
type: "metric_aggregation"
index: ".ds-metricbeat-*"
is_enabled: false

buffer_time:
  minutes: 3
metric_agg_key: "system.memory.used.pct"
metric_agg_type: max
max_threshold: 0.98

filter:
  - query:
      query_string:
        query: "system.memory.used.pct:*"

realert:
  minutes: 3

metric_format_string: "{:.3%}"

alert_text_type: alert_text_only
alert_subject: ":cat_feed: EC2 메모리 사용량 경고 :cat_feed:"
alert_text: ""

alert:
  - "mattermost"
mattermost_webhook_url: "https://meeting.ssafy.com/hooks/swkrw6fka7yxtyd3jxy96ejfne"
mattermost_channel_override: "ProjectAlarm"
mattermost_msg_color: "danger"
mattermost_msg_fields:
  - title: ":cat_feed: 쵸비이이이이이상!!! :cat_feed:"
    value: ":robot_cleaner_cat: 야 야, 너 서버 지금 터진다\n:robot_cleaner_cat: RAM 96% 이상 사용 - 터지기 직전!\n:robot_cleaner_cat: 현재 메모리 사용량: {0}"
    short: false
    args: [ "metric_agg_value_formatted" ]

```

### host-backend-alert.yml

- ERROR 로그가 1분 사이에 2번 이상 발생시 알람을 보내어 대처하도록 합니다.

```yaml
name: "Backend Log Alert"
type: "frequency"
index: "backend-*"
is_enabled: false

buffer_time:
  minutes: 1
num_events: 2
timeframe:
  minutes: 1

filter:
  - query:
      match_phrase:
        message: "ERROR "

realert:
  minutes: 5


alert_text_type: alert_text_only
alert_subject: ":7_nohara: Backend Error 발생 :7_nohara:"
alert_text: ""

alert:
  - "mattermost"
mattermost_webhook_url: "https://meeting.ssafy.com/hooks/swkrw6fka7yxtyd3jxy96ejfne"
mattermost_channel_override: "ProjectAlarm"
mattermost_msg_color: "danger"
mattermost_msg_fields:
  - title: ":7_nohara: 재영이형 카페와.. :7_nohara:"
    value: ":budrami_code_hmm: 어라? 백엔드 서버가 이상하다!\n:budrami_code_hmm: ERROR 가 나타났다! \n:budrami_code_hmm: 에러내용: {0}"
    short: false
    args: [ "message" ]

```